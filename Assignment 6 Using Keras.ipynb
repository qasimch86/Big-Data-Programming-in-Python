{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 'walk_or_run_train/train'\n",
    "test = 'walk_or_run_test/test'\n",
    "categories = ['walk','run']\n",
    "img_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "test_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path=os.path.join(train, category)\n",
    "        class_num=categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array=cv2.resize(img_array, (img_size, img_size))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    for category in categories:\n",
    "        path=os.path.join(DATADIR_TEST, category)\n",
    "        class_num=CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array=cv2.resize(img_array, (img_size,img_size))\n",
    "                test_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 45, 51, ..., 53, 46, 39],\n",
       "       [41, 47, 61, ..., 60, 49, 41],\n",
       "       [42, 38, 40, ..., 63, 53, 43],\n",
       "       ...,\n",
       "       [21, 30, 57, ..., 28, 23, 21],\n",
       "       [38, 49, 49, ..., 27, 21, 18],\n",
       "       [31, 28, 17, ..., 24, 21, 18]], dtype=uint8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in test_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of Normalizing the data another alternative is to use Convolutional neural network and maxpooling <br>\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))#3x3 filter<br>\n",
    "model.add(Activation('relu'))<br>\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tf.keras.utils.normalize(X_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x222273becf8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_array = X_train[5].reshape(img_size,img_size)\n",
    "plt.imshow(new_array,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel_initializer is used to create the initail weights and this can be<br>\n",
    "keras.initializers.Zeros()#creates zeros <br>\n",
    "keras.initializers.Ones()#creates ones<br>\n",
    "keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)#random numbers between -0.05 to 0.05 <br>\n",
    "keras.initializers.glorot_normal(seed=None)#uses Glorot normal initializer<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/initializers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    #first layer\n",
    "    keras.layers.Flatten(input_shape=(50, 50)),#shape of image,\n",
    "    keras.layers.Dense(256, kernel_initializer='random_uniform',bias_initializer='zeros',activation=tf.nn.relu),\n",
    "    #keras.layers.Dense(128,kernel_initializer=keras.initializers.Ones(),bias_initializer='zeros'),\n",
    "    #second layer\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    #third layer\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 540 samples, validate on 60 samples\n",
      "Epoch 1/30\n",
      "540/540 [==============================] - 0s 347us/step - loss: 0.2511 - acc: 0.9204 - val_loss: 1.0762 - val_acc: 0.4833\n",
      "Epoch 2/30\n",
      "540/540 [==============================] - 0s 366us/step - loss: 0.2458 - acc: 0.9389 - val_loss: 0.9921 - val_acc: 0.5833\n",
      "Epoch 3/30\n",
      "540/540 [==============================] - 0s 385us/step - loss: 0.2340 - acc: 0.9296 - val_loss: 1.0901 - val_acc: 0.5167\n",
      "Epoch 4/30\n",
      "540/540 [==============================] - 0s 393us/step - loss: 0.2349 - acc: 0.9241 - val_loss: 1.1194 - val_acc: 0.4833\n",
      "Epoch 5/30\n",
      "540/540 [==============================] - 0s 333us/step - loss: 0.2576 - acc: 0.9000 - val_loss: 0.9761 - val_acc: 0.6167\n",
      "Epoch 6/30\n",
      "540/540 [==============================] - 0s 329us/step - loss: 0.2312 - acc: 0.9167 - val_loss: 0.9925 - val_acc: 0.5833\n",
      "Epoch 7/30\n",
      "540/540 [==============================] - 0s 357us/step - loss: 0.2322 - acc: 0.9185 - val_loss: 1.2635 - val_acc: 0.4333\n",
      "Epoch 8/30\n",
      "540/540 [==============================] - 0s 320us/step - loss: 0.2417 - acc: 0.9111 - val_loss: 1.0273 - val_acc: 0.6667\n",
      "Epoch 9/30\n",
      "540/540 [==============================] - 0s 337us/step - loss: 0.2774 - acc: 0.8815 - val_loss: 1.0509 - val_acc: 0.6000\n",
      "Epoch 10/30\n",
      "540/540 [==============================] - 0s 275us/step - loss: 0.2498 - acc: 0.9056 - val_loss: 1.0160 - val_acc: 0.5833\n",
      "Epoch 11/30\n",
      "540/540 [==============================] - 0s 313us/step - loss: 0.2119 - acc: 0.9259 - val_loss: 1.0744 - val_acc: 0.6000\n",
      "Epoch 12/30\n",
      "540/540 [==============================] - 0s 275us/step - loss: 0.1960 - acc: 0.9611 - val_loss: 1.1739 - val_acc: 0.5333\n",
      "Epoch 13/30\n",
      "540/540 [==============================] - 0s 310us/step - loss: 0.1975 - acc: 0.9444 - val_loss: 1.0438 - val_acc: 0.6167\n",
      "Epoch 14/30\n",
      "540/540 [==============================] - 0s 386us/step - loss: 0.2113 - acc: 0.9315 - val_loss: 1.2593 - val_acc: 0.4667\n",
      "Epoch 15/30\n",
      "540/540 [==============================] - 0s 384us/step - loss: 0.1975 - acc: 0.9278 - val_loss: 1.2920 - val_acc: 0.4667\n",
      "Epoch 16/30\n",
      "540/540 [==============================] - 0s 313us/step - loss: 0.2262 - acc: 0.9111 - val_loss: 1.0708 - val_acc: 0.6500\n",
      "Epoch 17/30\n",
      "540/540 [==============================] - 0s 373us/step - loss: 0.2090 - acc: 0.9278 - val_loss: 1.0816 - val_acc: 0.5833\n",
      "Epoch 18/30\n",
      "540/540 [==============================] - 0s 420us/step - loss: 0.1759 - acc: 0.9500 - val_loss: 1.2154 - val_acc: 0.5500\n",
      "Epoch 19/30\n",
      "540/540 [==============================] - 0s 357us/step - loss: 0.1568 - acc: 0.9593 - val_loss: 1.3583 - val_acc: 0.4833\n",
      "Epoch 20/30\n",
      "540/540 [==============================] - 0s 367us/step - loss: 0.1543 - acc: 0.9667 - val_loss: 1.1149 - val_acc: 0.5667\n",
      "Epoch 21/30\n",
      "540/540 [==============================] - 0s 369us/step - loss: 0.1545 - acc: 0.9611 - val_loss: 1.2349 - val_acc: 0.5500\n",
      "Epoch 22/30\n",
      "540/540 [==============================] - 0s 340us/step - loss: 0.1602 - acc: 0.9667 - val_loss: 1.3718 - val_acc: 0.4833\n",
      "Epoch 23/30\n",
      "540/540 [==============================] - 0s 301us/step - loss: 0.1624 - acc: 0.9444 - val_loss: 1.1567 - val_acc: 0.6000\n",
      "Epoch 24/30\n",
      "540/540 [==============================] - 0s 307us/step - loss: 0.1319 - acc: 0.9759 - val_loss: 1.2772 - val_acc: 0.5333\n",
      "Epoch 25/30\n",
      "540/540 [==============================] - 0s 436us/step - loss: 0.1361 - acc: 0.9685 - val_loss: 1.3065 - val_acc: 0.5333\n",
      "Epoch 26/30\n",
      "540/540 [==============================] - 0s 368us/step - loss: 0.1296 - acc: 0.9778 - val_loss: 1.2379 - val_acc: 0.6167\n",
      "Epoch 27/30\n",
      "540/540 [==============================] - 0s 334us/step - loss: 0.1339 - acc: 0.9685 - val_loss: 1.1737 - val_acc: 0.6000\n",
      "Epoch 28/30\n",
      "540/540 [==============================] - 0s 450us/step - loss: 0.1295 - acc: 0.9611 - val_loss: 1.1917 - val_acc: 0.5667\n",
      "Epoch 29/30\n",
      "540/540 [==============================] - 0s 444us/step - loss: 0.1299 - acc: 0.9704 - val_loss: 1.3522 - val_acc: 0.5333\n",
      "Epoch 30/30\n",
      "540/540 [==============================] - 0s 477us/step - loss: 0.1100 - acc: 0.9796 - val_loss: 1.2338 - val_acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2223f8b3cf8>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model\n",
    "model.fit(X_train, y_train, batch_size=100, epochs=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 700us/step\n",
      "Test accuracy: 0.5673758871589146\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc=model.evaluate(x_test,y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_classes(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.15.2 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.9.3 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from seaborn) (1.15.4)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from seaborn) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2018.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.15.2->seaborn) (1.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\oa87046\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=confusion_matrix(y_test, Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 19],\n",
       "       [42, 40]], dtype=int64)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-205-6c3715eaf684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
